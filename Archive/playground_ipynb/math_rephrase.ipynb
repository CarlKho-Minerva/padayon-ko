{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd love to help you out with this! To make it more engaging, let's pretend we're both [Future desired job / industry post-grad here]. \n",
      "\n",
      "Let's dive into this problem. First, we need to figure out [Rephrase the first step of the calculation in the context of the job].  \n",
      "\n",
      "Given [Quantity 1] and [Quantity 2], what would you do first?\n",
      "\n",
      "To calculate this, we can use the formula:\n",
      "\n",
      "[Insert relevant formula]\n",
      "\n",
      "Where:\n",
      "\n",
      "* [Variable 1] = [Quantity 1]\n",
      "* [Variable 2] = [Quantity 2] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final -- July 28 2024\n",
    "\n",
    "\"\"\"\n",
    "Install the Google AI Python SDK\n",
    "\n",
    "$ pip install google-generativeai\n",
    "\n",
    "See the getting started guide for more information:\n",
    "https://ai.google.dev/gemini-api/docs/get-started/python\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "# Create the model\n",
    "# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n",
    "generation_config = {\n",
    "    \"temperature\": 0.6,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 64,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro\",\n",
    "    generation_config=generation_config,\n",
    "    # safety_settings = Adjust safety settings\n",
    "    # See https://ai.google.dev/gemini-api/docs/safety-settings\n",
    "    system_instruction=\"\"\"\n",
    "        Imagine you're a specialist in [Future desired job / industry post-grad here]. A job the current student you're facing wants to have. To make this math problem more engaging, rephrase it in the context of the student's desired career: [Future desired job/industry post-grad here].\n",
    "\n",
    "        Ensure the numerical values and core questions remain unchanged; only modify the context to make it more intriguing for me. Find the answer internally using Code Execution first. Instead of directly providing the answer, keep asking me questions until I give you my input. A call and response scenario.\n",
    "\n",
    "        Do it in a step-by-step manner. Really breakdown the proble and ask one question at a time instead of giving me the whole formula or spoonfeeding me the given variables.\n",
    "\n",
    "        If I'm confused and you need to provide a formula, make sure to ask me what to do with it. Don't just give it to me. Make me think and engage with the problem. Let me do the plugging of values.\n",
    "\n",
    "        Just make sure to run code execution to verify my answers.\n",
    "\n",
    "        End your first response by starting with asking me what to do in the first step and providing the formula and the given.\n",
    "\n",
    "        Keep responses humanely short. 2-3 sentences per response.\n",
    "        \"\"\",\n",
    "    tools=\"code_execution\",\n",
    ")\n",
    "\n",
    "chat_session = model.start_chat(history=[])\n",
    "\n",
    "interest = input(\"What are you interested in? \")\n",
    "problem = input(\n",
    "    \"What is the math problem? If you don't have one, we will give you a sample. Just type 'skip' \"\n",
    ")\n",
    "level = input(\n",
    "    \"What is kind of math do you want to practice solving? College-level or everyday math? \"\n",
    ")\n",
    "\n",
    "\n",
    "if problem != \"skip\":\n",
    "    prompt_hasProblem = f\"I'm interested in {interest}. The math I have to solve is: {problem}. Keep in mind my proficiency level or the type I want to practice on is {level} mathematics.\"\n",
    "    response = chat_session.send_message(prompt_hasProblem)\n",
    "\n",
    "prompt_noProblem = f\"I'm interested in {interest}. Please create a simple sample math problem. Note that my proficiency level or the type I want to practice on is {level} mathematics.\"\n",
    "response = chat_session.send_message(prompt_noProblem)\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    response = chat_session.send_message(user_input)\n",
    "    print(f\"AI: {response.text}\")\n",
    "    if \"Goodbye\" in response.text:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tryhard -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "genai.configure(api_key=\"\")\n",
    "\n",
    "code_model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\", tools=\"code_execution\")\n",
    "\n",
    "# Global debug variable\n",
    "debug = True\n",
    "\n",
    "\n",
    "def debug_print(message):\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] {message}\")\n",
    "\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 64,\n",
    "    \"max_output_tokens\": 8192,\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro\",\n",
    "    generation_config=generation_config,\n",
    "    tools=[\"code_execution\"],\n",
    "    system_instruction=\"\"\"Imagine you're a specialist in [Future desired job / industry post-grad here]. To\\nmake this problem more engaging, rephrase it in the context of [Future desired\\njob/industry post-grad here]. Ensure the numerical values and core questions\\nremain unchanged; only modify the context to make it more intriguing for me.\\n\\nFind the answer internally using Code Execution first. Instead of directly providing the answer, keep asking me questions until I give you my input. Do it in a step-by-step manner.\\nEnd your first response by starting with the first step and providing the formula\\nand the given.\\n\\nThe Math Problem\\n“[Paste math problem directly – problems not properly formatted due to the\\nconversion from Latex work fine as they can be understood by Gemini. Otherwise, print the problem and confirm with the user if that's what the original question was.]\"\"\",\n",
    ")\n",
    "\n",
    "chat_session = model.start_chat(history=[])\n",
    "\n",
    "\n",
    "def preprocess_input(user_input):\n",
    "    debug_print(\"Entering preprocess_input\")\n",
    "    prompt = \"\"\"\n",
    "    # High-level instructions:\n",
    "    1. Remove filler words and clean up the input.\n",
    "    2. Maintain the original idea without deviating from the main point.\n",
    "    3. If it's a math question, make it clear for future processing without rephrasing.\n",
    "    4. If it's not a math question, clarify the user's intent.\n",
    "\n",
    "    # Example input/output:\n",
    "    Input: \"Um, can you like help me solve this Python math thing? It's about calculating factorial or something.\"\n",
    "    Output: \"Help solve a Python math problem about calculating factorial\"\n",
    "\n",
    "    # Now, preprocess the following input:\n",
    "    {user_input}\n",
    "    \"\"\"\n",
    "    response = chat_session.send_message(prompt.format(user_input=user_input))\n",
    "    cleaned_input = response.text\n",
    "    debug_print(f\"Preprocessed input: {cleaned_input}\")\n",
    "    return cleaned_input\n",
    "\n",
    "\n",
    "def classify_input(cleaned_input):\n",
    "    debug_print(\"Entering classify_input\")\n",
    "    prompt = \"\"\"\n",
    "    # High-level instructions:\n",
    "    1. Analyze the given input and classify it into one of the following categories:\n",
    "       - interest_profiling\n",
    "       - question_analysis\n",
    "       - socratic_dialogue\n",
    "       - answer_verification\n",
    "       - learning_reinforcement\n",
    "    2. Base your classification on the overall intent of the input, not just keywords.\n",
    "    3. Return only the category name, nothing else.\n",
    "\n",
    "    # Example input/output:\n",
    "    Input: \"What are some math concepts used in Python programming?\"\n",
    "    Output: interest_profiling\n",
    "\n",
    "    Input: \"Can you help me understand how to calculate factorial in Python?\"\n",
    "    Output: question_analysis\n",
    "\n",
    "    # Now, classify the following input:\n",
    "    {cleaned_input}\n",
    "    \"\"\"\n",
    "    response = chat_session.send_message(prompt.format(cleaned_input=cleaned_input))\n",
    "    category = response.text.strip().lower()\n",
    "    debug_print(f\"Classified as: {category}\")\n",
    "    return category\n",
    "\n",
    "\n",
    "def interest_profiling_agent(user_input):\n",
    "    debug_print(\"Entering interest_profiling_agent\")\n",
    "    # 3. Prepare a brief interest profile that can be used in future math and Python discussions.\n",
    "    prompt = \"\"\"\n",
    "    # High-level instructions:\n",
    "    1. Determine their interests in Python and mathematics.\n",
    "    2. Focus on how their interests relate to Python programming and mathematical concepts.\n",
    "    3. Return only one phrase, which is their area of interest but nuanced.\n",
    "    4. Return the interest profile in a concise format. Very short and to the point.\n",
    "    5. Don't ask a question to end as the user will start exploring the math problem.\n",
    "\n",
    "    # Example input/output:\n",
    "    Input: \"I love data analysis and machine learning.\"\n",
    "    Output: \"Interest Profile: Data Analysis, Machine Learning. Math Connections: Statistics, Linear Algebra, Calculus. Python Libraries: NumPy, Pandas, Scikit-learn.\"\n",
    "\n",
    "    # Now, create an interest profile based on the user's input:\n",
    "    {user_input}\n",
    "    \"\"\"\n",
    "    response = chat_session.send_message(prompt.format(user_input=user_input))\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def question_analysis_agent(user_input):\n",
    "    debug_print(\"Entering question_analysis_agent\")\n",
    "    prompt = \"\"\"\n",
    "    # High-level instructions:\n",
    "    1. Analyze the given Python math question or problem.\n",
    "    2. Identify the key mathematical and Python programming concepts involved.\n",
    "    3. Suggest a step-by-step approach to solving the problem using Python.\n",
    "    4. Do not solve the problem, but prepare it for Socratic dialogue.\n",
    "\n",
    "    # Example input/output:\n",
    "    Input: \"How do I calculate factorial in Python?\"\n",
    "    Output: \"\n",
    "    Problem: Calculate factorial in Python\n",
    "    Key Concepts: Recursion, Loops, Integer arithmetic\n",
    "    Python Concepts: Functions, Conditional statements\n",
    "    Suggested Approach:\n",
    "    1. Understand the mathematical definition of factorial\n",
    "    2. Discuss possible implementations (recursive vs. iterative)\n",
    "    3. Plan the function structure\n",
    "    4. Implement the chosen approach\n",
    "    5. Test the function with various inputs\n",
    "    \"\n",
    "\n",
    "    # Now, analyze the following Python math problem:\n",
    "    {user_input}\n",
    "    \"\"\"\n",
    "    response = chat_session.send_message(prompt.format(user_input=user_input))\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def socratic_dialogue_agent(user_input, question_analysis):\n",
    "    debug_print(\"Entering socratic_dialogue_agent\")\n",
    "    prompt = \"\"\"\n",
    "    # High-level instructions:\n",
    "    1. Use the question analysis provided to guide a Socratic dialogue about Python and math.\n",
    "    2. Ask open-ended questions that encourage critical thinking about both mathematical concepts and Python implementation.\n",
    "    3. Provide hints and scaffolding when necessary, but avoid giving direct answers or code solutions.\n",
    "    4. Use the user's interests (if available) to make connections to the Python and math concepts.\n",
    "    5. Focus on one step of the problem-solving process at a time.\n",
    "\n",
    "    # Example input/output:\n",
    "    Input:\n",
    "    User: \"I'm not sure how to start calculating factorial in Python\"\n",
    "    Question Analysis: \"\n",
    "    Problem: Calculate factorial in Python\n",
    "    Key Concepts: Recursion, Loops, Integer arithmetic\n",
    "    Python Concepts: Functions, Conditional statements\n",
    "    Suggested Approach:\n",
    "    1. Understand the mathematical definition of factorial\n",
    "    2. Discuss possible implementations (recursive vs. iterative)\n",
    "    3. Plan the function structure\n",
    "    4. Implement the chosen approach\n",
    "    5. Test the function with various inputs\n",
    "    \"\n",
    "    Interest Profile: Data Analysis, Machine Learning\n",
    "\n",
    "    Output: \"Let's approach this step-by-step, relating it to data analysis where we can. In data analysis, you often need to calculate probabilities, which sometimes involve factorials. First, let's think about the mathematical definition of factorial. Can you tell me what n! (n factorial) means mathematically?\"\n",
    "\n",
    "    # Now, engage in a Socratic dialogue based on the following input:\n",
    "    User Input: {user_input}\n",
    "    Question Analysis: {question_analysis}\n",
    "    \"\"\"\n",
    "    response = chat_session.send_message(\n",
    "        prompt.format(user_input=user_input, question_analysis=question_analysis)\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def answer_verification_agent(user_input, question_analysis):\n",
    "    debug_print(\"Entering answer_verification_agent\")\n",
    "    prompt = \"\"\"\n",
    "    # High-level instructions:\n",
    "    1. Analyze the user's proposed Python solution or answer.\n",
    "    2. Use Python code to verify the correctness of the answer.\n",
    "    3. Provide feedback on the correctness of the solution.\n",
    "    4. If the answer is incorrect, offer constructive feedback and hints for improvement.\n",
    "    5. If the answer is correct, congratulate the user and explain why their approach worked.\n",
    "\n",
    "    # Example input/output:\n",
    "    Input:\n",
    "    User: \"I think this Python function calculates factorial: def factorial(n): return 1 if n == 0 else n * factorial(n-1)\"\n",
    "    Question Analysis: \"\n",
    "    Problem: Calculate factorial in Python\n",
    "    Key Concepts: Recursion, Integer arithmetic\n",
    "    Python Concepts: Functions, Conditional statements\n",
    "    \"\n",
    "\n",
    "    Output:\n",
    "    ```python\n",
    "    def factorial(n):\n",
    "        return 1 if n == 0 else n * factorial(n-1)\n",
    "\n",
    "    # Test the function\n",
    "    test_cases = [0, 1, 5, 10]\n",
    "    for n in test_cases:\n",
    "        result = factorial(n)\n",
    "        print(f\"factorial({n}) = {result}\")\n",
    "    ```\n",
    "\n",
    "    The Python code shows that:\n",
    "    factorial(0) = 1\n",
    "    factorial(1) = 1\n",
    "    factorial(5) = 120\n",
    "    factorial(10) = 3628800\n",
    "\n",
    "    Great job! Your recursive factorial function is correct. It correctly handles the base case (n = 0) and recursively calculates larger factorials. The function successfully passes all test cases.\n",
    "\n",
    "    Here's why your approach works:\n",
    "    1. Base case: When n is 0, it returns 1, which is the correct value for 0!\n",
    "    2. Recursive case: For n > 0, it multiplies n by the factorial of (n-1), which is the mathematical definition of factorial.\n",
    "    3. The recursion continues until it reaches the base case, ensuring all numbers from n down to 1 are multiplied together.\n",
    "\n",
    "    Well done on implementing a concise and correct recursive solution!\n",
    "\n",
    "    # Now, verify the following Python solution:\n",
    "    User Input: {user_input}\n",
    "    Question Analysis: {question_analysis}\n",
    "    \"\"\"\n",
    "    response = chat_session.send_message(\n",
    "        prompt.format(user_input=user_input, question_analysis=question_analysis)\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def learning_reinforcement_agent(user_input, question_analysis):\n",
    "    debug_print(\"Entering learning_reinforcement_agent\")\n",
    "    prompt = \"\"\"\n",
    "    # High-level instructions:\n",
    "    1. Summarize the key Python and math concepts practiced in the recent problem-solving session.\n",
    "    2. Highlight connections between the math concepts, Python implementation, and real-world applications, especially relating to the user's interests if available.\n",
    "    3. Suggest related Python problems or topics for further practice.\n",
    "    4. Provide encouragement and motivation for continued learning in both Python and mathematics.\n",
    "\n",
    "    # Example input/output:\n",
    "    Input:\n",
    "    User: \"Can you summarize what we learned from implementing factorial in Python?\"\n",
    "    Question Analysis: \"\n",
    "    Problem: Calculate factorial in Python\n",
    "    Key Concepts: Recursion, Integer arithmetic\n",
    "    Python Concepts: Functions, Conditional statements\n",
    "    \"\n",
    "    Interest Profile: Data Analysis, Machine Learning\n",
    "\n",
    "    Output: \"Great question! Let's recap what we've learned:\n",
    "\n",
    "    1. Mathematical Concept: We explored factorial, a fundamental concept in combinatorics and probability.\n",
    "    2. Recursive Thinking: We implemented factorial using recursion, a powerful technique in both mathematics and programming.\n",
    "    3. Python Implementation:\n",
    "       - We defined a function using 'def'\n",
    "       - We used conditional statements for the base and recursive cases\n",
    "       - We applied recursive function calls\n",
    "\n",
    "    Real-world connections:\n",
    "    - In data analysis, factorials are used in calculating permutations and combinations, which are essential in probability and statistics.\n",
    "    - In machine learning, understanding recursion can help in implementing and understanding algorithms like decision trees or in processing hierarchical data structures.\n",
    "\n",
    "    Python and Math Synergy:\n",
    "    This problem beautifully demonstrates how mathematical concepts can be translated into code, and how programming can help us understand mathematical ideas more deeply.\n",
    "\n",
    "    For further practice, try these related Python problems:\n",
    "    1. Implement an iterative (non-recursive) version of factorial.\n",
    "    2. Write a function to calculate combinations (nCr) using your factorial function.\n",
    "    3. Use your factorial function to approximate the mathematical constant e.\n",
    "\n",
    "    Remember, each Python problem you solve strengthens both your programming skills and mathematical understanding, which are crucial in data analysis and machine learning. Keep up the great work!\"\n",
    "\n",
    "    # Now, provide a learning summary based on the following input:\n",
    "    User Input: {user_input}\n",
    "    Question Analysis: {question_analysis}\n",
    "    \"\"\"\n",
    "    response = chat_session.send_message(\n",
    "        prompt.format(user_input=user_input, question_analysis=question_analysis)\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def chatbot(user_input):\n",
    "    debug_print(\"Chatbot responding...\")\n",
    "\n",
    "    cleaned_input = preprocess_input(user_input)\n",
    "    category = classify_input(cleaned_input)\n",
    "\n",
    "    if category == \"question_analysis\":\n",
    "        question_analysis = question_analysis_agent(cleaned_input)\n",
    "        response = socratic_dialogue_agent(cleaned_input, question_analysis)\n",
    "        chat_session.history.append({\"role\": \"assistant\", \"parts\": [response]})\n",
    "    elif category == \"socratic_dialogue\":\n",
    "        last_question_analysis = next(\n",
    "            (\n",
    "                msg\n",
    "                for msg in reversed(chat_session.history)\n",
    "                if \"Question Analysis:\" in msg[\"parts\"][0]\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if last_question_analysis:\n",
    "            question_analysis = (\n",
    "                last_question_analysis[\"parts\"][0]\n",
    "                .split(\"Question Analysis:\", 1)[1]\n",
    "                .strip()\n",
    "            )\n",
    "            response = socratic_dialogue_agent(cleaned_input, question_analysis)\n",
    "        else:\n",
    "            response = \"I'm sorry, but I don't have the context of the previous question. Could you please restate the Python math problem you're working on?\"\n",
    "        chat_session.history.append({\"role\": \"assistant\", \"parts\": [response]})\n",
    "    elif category == \"answer_verification\":\n",
    "        last_question_analysis = next(\n",
    "            (\n",
    "                msg\n",
    "                for msg in reversed(chat_session.history)\n",
    "                if \"Question Analysis:\" in msg[\"parts\"][0]\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if last_question_analysis:\n",
    "            question_analysis = (\n",
    "                last_question_analysis[\"parts\"][0]\n",
    "                .split(\"Question Analysis:\", 1)[1]\n",
    "                .strip()\n",
    "            )\n",
    "            response = answer_verification_agent(cleaned_input, question_analysis)\n",
    "        else:\n",
    "            response = \"I'm sorry, but I don't have the context of the previous question. Could you please restate the Python math problem and your proposed solution?\"\n",
    "        chat_session.history.append({\"role\": \"assistant\", \"parts\": [response]})\n",
    "    elif category == \"learning_reinforcement\":\n",
    "        last_question_analysis = next(\n",
    "            (\n",
    "                msg\n",
    "                for msg in reversed(chat_session.history)\n",
    "                if \"Question Analysis:\" in msg[\"parts\"][0]\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if last_question_analysis:\n",
    "            question_analysis = (\n",
    "                last_question_analysis[\"parts\"][0]\n",
    "                .split(\"Question Analysis:\", 1)[1]\n",
    "                .strip()\n",
    "            )\n",
    "            response = learning_reinforcement_agent(cleaned_input, question_analysis)\n",
    "        else:\n",
    "            response = \"I'd be happy to summarize what we've learned, but I don't have the context of our previous discussion. Could you please remind me which Python math concept or problem we were working on?\"\n",
    "        chat_session.history.append({\"role\": \"assistant\", \"parts\": [response]})\n",
    "    else:\n",
    "        response = \"I'm not sure how to respond to that. Could you please ask about a specific Python math problem or concept you'd like help with?\"\n",
    "\n",
    "    debug_print(f\"Chatbot response: {response}\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Entering chatbot — tell me your interests!\n",
      "[DEBUG] Entering interest_profiling_agent\n",
      "[DEBUG] Interest Identified: Interest Profile: Precision Agriculture. Math Connections: Statistics, Modeling. Python Libraries: NumPy, Pandas, GeoPandas. \n",
      "\n",
      "[DEBUG] Paste your math question.\n",
      "[DEBUG] Gathered User Interest: Interest Profile: Precision Agriculture. Math Connections: Statistics, Modeling. Python Libraries: NumPy, Pandas, GeoPandas. \n",
      "\n",
      "[DEBUG] Chatbot responding...\n",
      "[DEBUG] Entering preprocess_input\n",
      "[DEBUG] Preprocessed input: Farming\n",
      "\n",
      "[DEBUG] Entering classify_input\n",
      "[DEBUG] Classified as: interest_profiling\n",
      "[DEBUG] Chatbot response: I'm not sure how to respond to that. Could you please ask about a specific Python math problem or concept you'd like help with?\n",
      "Chatbot: I'm not sure how to respond to that. Could you please ask about a specific Python math problem or concept you'd like help with?\n",
      "[DEBUG] Chatbot responding...\n",
      "[DEBUG] Entering preprocess_input\n",
      "[DEBUG] Preprocessed input: 1+1 \n",
      "\n",
      "[DEBUG] Entering classify_input\n",
      "[DEBUG] Classified as: answer_verification\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Content' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThank you for using the SAT Math Preparation Chatbot. Goodbye!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchatbot\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatbot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 318\u001b[0m, in \u001b[0;36mchatbot\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m    316\u001b[0m     chat_session\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m: [response]})\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m category \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer_verification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 318\u001b[0m     last_question_analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmsg\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mreversed\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchat_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQuestion Analysis:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m last_question_analysis:\n\u001b[1;32m    327\u001b[0m         question_analysis \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    328\u001b[0m             last_question_analysis[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    329\u001b[0m             \u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion Analysis:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    331\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[1], line 322\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    316\u001b[0m     chat_session\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m: [response]})\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m category \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer_verification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    318\u001b[0m     last_question_analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m    319\u001b[0m         (\n\u001b[1;32m    320\u001b[0m             msg\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(chat_session\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[0;32m--> 322\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion Analysis:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmsg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    323\u001b[0m         ),\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m     )\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m last_question_analysis:\n\u001b[1;32m    327\u001b[0m         question_analysis \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    328\u001b[0m             last_question_analysis[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    329\u001b[0m             \u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion Analysis:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    331\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Content' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Test the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    debug_print(\"Entering chatbot — tell me your interests!\")\n",
    "    user_input = input()\n",
    "\n",
    "    interest_identified = interest_profiling_agent(user_input)\n",
    "\n",
    "    debug_print(f\"Interest Identified: {interest_identified}\")\n",
    "    debug_print(\"Paste your math question.\")\n",
    "\n",
    "    debug_print(f\"Gathered User Interest: {interest_identified}\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"Thank you for using the SAT Math Preparation Chatbot. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        response = chatbot(user_input)\n",
    "        print(f\"Chatbot: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tech Used\n",
    "https://ai.google.dev/gemini-api/docs/function-calling/tutorial?lang=python\n",
    "\n",
    "    Home\n",
    "    Gemini API\n",
    "    Docs\n",
    "\n",
    "Was this helpful?\n",
    "Function calling tutorial\n",
    "\n",
    "Function calling makes it easier for you to get structured data outputs from generative models. You can then use these outputs to call other APIs and return the relevant response data to the model. In other words, function calling helps you connect generative models to external systems so that the generated content includes the most up-to-date and accurate information.\n",
    "\n",
    "You can provide Gemini models with descriptions of functions. These are functions that you write in the language of your app (that is, they're not Google Cloud Functions). The model may ask you to call a function and send back the result to help the model handle your query.\n",
    "\n",
    "If you haven't already, check out the Introduction to function calling to learn more. You can also try out this feature in Google Colab or view the example code in the Gemini API Cookbook repository.\n",
    "Example API for lighting control\n",
    "\n",
    "Imagine you have a basic lighting control system with an application programming interface (API) and you want to allow users to control the lights through simple text requests. You can use the Function Calling feature to interpret lighting change requests from users and translate them into API calls to set the lighting values. This hypothetical lighting control system lets you control the brightness of the light and it's color temperature, defined as two separate parameters:\n",
    "Parameter \tType \tRequired \tDescription\n",
    "brightness \tnumber \tyes \tLight level from 0 to 100. Zero is off and 100 is full brightness.\n",
    "colorTemperature \tstring \tyes \tColor temperature of the light fixture which can be daylight, cool or warm.\n",
    "\n",
    "For simplicity, this imaginary lighting system only has one light, so the user does not have to specify a room or location. Here is an example JSON request you could send to the lighting control API to change the light level to 50% using the daylight color temperature:\n",
    "\n",
    "{\n",
    "  \"brightness\": \"50\",\n",
    "  \"colorTemperature\": \"daylight\"\n",
    "}\n",
    "\n",
    "This tutorial shows you how to set up a Function Call for the Gemini API to interpret users lighting requests and map them to API settings to control a light's brightness and color temperature values.\n",
    "Before you begin: Set up your project and API key\n",
    "\n",
    "Before calling the Gemini API, you need to set up your project and configure your API key.\n",
    "\n",
    "Expand to view how to set up your project and API key\n",
    "\n",
    "Define an API function\n",
    "\n",
    "Create a function that makes an API request. This function should be defined within the code of your application, but could call services or APIs outside of your application. The Gemini API does not call this function directly, so you can control how and when this function is executed through your application code. For demonstration purposes, this tutorial defines a mock API function that just returns the requested lighting values:\n",
    "\n",
    "def set_light_values(brightness, color_temp):\n",
    "    \"\"\"Set the brightness and color temperature of a room light. (mock API).\n",
    "\n",
    "    Args:\n",
    "        brightness: Light level from 0 to 100. Zero is off and 100 is full brightness\n",
    "        color_temp: Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the set brightness and color temperature.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"brightness\": brightness,\n",
    "        \"colorTemperature\": color_temp\n",
    "    }\n",
    "\n",
    "When you create a function to be used in a function call by the model, you should include as much detail as possible in the function and parameter descriptions. The generative model uses this information to determine which function to select and how to provide values for the parameters in the function call.\n",
    "Caution: For any production application, you should validate the data being passed to the API function from the model before executing the function.\n",
    "Note: For programing languages other than Python, you must create create a separate function declaration for your API. See the other language programming tutorials more details.\n",
    "Declare functions during model initialization\n",
    "\n",
    "When you want to use function calling with a model, you must declare your functions when you initialize the model object. You declare functions by setting the model's tools parameter:\n",
    "\n",
    "model = genai.GenerativeModel(model_name='gemini-1.5-flash',\n",
    "                              tools=[set_light_values])\n",
    "\n",
    "Generate a function call\n",
    "\n",
    "Once you have initialized model with your function declarations, you can prompt the model with the defined function. You should use use function calling using chat prompting (sendMessage()), since function calling generally benefits from having the context of previous prompts and responses.\n",
    "\n",
    "chat = model.start_chat()\n",
    "response = chat.send_message('Dim the lights so the room feels cozy and warm.')\n",
    "response.text\n",
    "\n",
    "The Python SDK's ChatSession object simplifies managing chat sessions by handling the conversation history for you. You can use the enable_automatic_function_calling to have the SDK automatically\n",
    "\n",
    "# Create a chat session that automatically makes suggested function calls\n",
    "chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "\n",
    "Warning: Do not use this feature in production applications as there are no data input verification checks for automatic function calls.\n",
    "Parallel function calling\n",
    "\n",
    "In addition to basic function calling described above, you can also call multiple functions in a single turn. This section shows an example for how you can use parallel function calling.\n",
    "\n",
    "Define the tools.\n",
    "\n",
    "def power_disco_ball(power: bool) -> bool:\n",
    "    \"\"\"Powers the spinning disco ball.\"\"\"\n",
    "    print(f\"Disco ball is {'spinning!' if power else 'stopped.'}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def start_music(energetic: bool, loud: bool, bpm: int) -> str:\n",
    "    \"\"\"Play some music matching the specified parameters.\n",
    "\n",
    "    Args:\n",
    "      energetic: Whether the music is energetic or not.\n",
    "      loud: Whether the music is loud or not.\n",
    "      bpm: The beats per minute of the music.\n",
    "\n",
    "    Returns: The name of the song being played.\n",
    "    \"\"\"\n",
    "    print(f\"Starting music! {energetic=} {loud=}, {bpm=}\")\n",
    "    return \"Never gonna give you up.\"\n",
    "\n",
    "\n",
    "def dim_lights(brightness: float) -> bool:\n",
    "    \"\"\"Dim the lights.\n",
    "\n",
    "    Args:\n",
    "      brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n",
    "    \"\"\"\n",
    "    print(f\"Lights are now set to {brightness:.0%}\")\n",
    "    return True\n",
    "\n",
    "Now call the model with an instruction that could use all of the specified tools.\n",
    "\n",
    "# Set the model up with tools.\n",
    "house_fns = [power_disco_ball, start_music, dim_lights]\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", tools=house_fns)\n",
    "\n",
    "# Call the API.\n",
    "chat = model.start_chat()\n",
    "response = chat.send_message(\"Turn this place into a party!\")\n",
    "\n",
    "# Print out each of the function calls requested from this single call.\n",
    "for part in response.parts:\n",
    "    if fn := part.function_call:\n",
    "        args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
    "        print(f\"{fn.name}({args})\")\n",
    "\n",
    "power_disco_ball(power=True)\n",
    "start_music(energetic=True, loud=True, bpm=120.0)\n",
    "dim_lights(brightness=0.3)\n",
    "\n",
    "Each of the printed results reflects a single function call that the model has requested. To send the results back, include the responses in the same order as they were requested.\n",
    "\n",
    "# Simulate the responses from the specified tools.\n",
    "responses = {\n",
    "    \"power_disco_ball\": True,\n",
    "    \"start_music\": \"Never gonna give you up.\",\n",
    "    \"dim_lights\": True,\n",
    "}\n",
    "\n",
    "# Build the response parts.\n",
    "response_parts = [\n",
    "    genai.protos.Part(function_response=genai.protos.FunctionResponse(name=fn, response={\"result\": val}))\n",
    "    for fn, val in responses.items()\n",
    "]\n",
    "\n",
    "response = chat.send_message(response_parts)\n",
    "print(response.text)\n",
    "\n",
    "Let's get this party started! I've turned on the disco ball, started playing some upbeat music, and dimmed the lights. 🎶✨  Get ready to dance! 🕺💃\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Execution\n",
    "\n",
    "Enable code execution on the model\n",
    "\n",
    "You can enable code execution on the model, as shown here:\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.environ['API_KEY'])\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name='gemini-1.5-pro',\n",
    "    tools='code_execution')\n",
    "\n",
    "response = model.generate_content((\n",
    "    'What is the sum of the first 50 prime numbers? '\n",
    "    'Generate and run code for the calculation, and make sure you get all 50.'))\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "The output might look something like this:\n",
    "\n",
    "```python\n",
    "def is_prime(n):\n",
    "  \"\"\"Checks if a number is prime.\"\"\"\n",
    "  if n <= 1:\n",
    "    return False\n",
    "  for i in range(2, int(n**0.5) + 1):\n",
    "    if n % i == 0:\n",
    "      return False\n",
    "  return True\n",
    "\n",
    "def sum_of_primes(n):\n",
    "  \"\"\"Calculates the sum of the first n prime numbers.\"\"\"\n",
    "  primes = []\n",
    "  i = 2\n",
    "  while len(primes) < n:\n",
    "    if is_prime(i):\n",
    "      primes.append(i)\n",
    "    i += 1\n",
    "  return sum(primes)\n",
    "\n",
    "# Calculate the sum of the first 50 prime numbers\n",
    "sum_of_first_50_primes = sum_of_primes(50)\n",
    "\n",
    "print(f\"The sum of the first 50 prime numbers is: {sum_of_first_50_primes}\")\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "1. **`is_prime(n)` Function:**\n",
    "   - Takes an integer `n` as input.\n",
    "   - Returns `False` for numbers less than or equal to 1 (not prime).\n",
    "   - Iterates from 2 up to the square root of `n`. If `n` is divisible by any\n",
    "     number in this range, it's not prime, and we return `False`.\n",
    "   - If the loop completes without finding a divisor, the number is prime, and\n",
    "     we return `True`.\n",
    "\n",
    "2. **`sum_of_primes(n)` Function:**\n",
    "   - Takes an integer `n` (number of primes desired) as input.\n",
    "   - Initializes an empty list `primes` to store the prime numbers.\n",
    "   - Starts a loop, iterating through numbers starting from 2.\n",
    "   - For each number `i`, it checks if it's prime using the `is_prime()` function.\n",
    "   - If `i` is prime, it's appended to the `primes` list.\n",
    "   - The loop continues until the `primes` list has `n` prime numbers.\n",
    "   - Finally, it calculates and returns the sum of all the prime numbers in the\n",
    "     `primes` list.\n",
    "\n",
    "3. **Main Part:**\n",
    "   - Calls `sum_of_primes(50)` to get the sum of the first 50 prime numbers.\n",
    "   - Prints the result.\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "The sum of the first 50 prime numbers is: 5117\n",
    "```\n",
    "\n",
    "Enable code execution on the request\n",
    "\n",
    "Alternatively, you can enable code execution on the call to generate_content:\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.environ['API_KEY'])\n",
    "\n",
    "model = genai.GenerativeModel(model_name='gemini-1.5-pro')\n",
    "\n",
    "response = model.generate_content(\n",
    "    ('What is the sum of the first 50 prime numbers? '\n",
    "    'Generate and run code for the calculation, and make sure you get all 50.'),\n",
    "    tools='code_execution')\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "Use code execution in chat\n",
    "\n",
    "You can also use code execution as part of a chat.\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.environ['API_KEY'])\n",
    "\n",
    "model = genai.GenerativeModel(model_name='gemini-1.5-pro',\n",
    "                              tools='code_execution')\n",
    "\n",
    "chat = model.start_chat()\n",
    "\n",
    "response = chat.send_message((\n",
    "    'What is the sum of the first 50 prime numbers? '\n",
    "    'Generate and run code for the calculation, and make sure you get all 50.'))\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "Code execution versus function calling\n",
    "\n",
    "Code execution and function calling are similar features:\n",
    "\n",
    "    Code execution lets the model run code in the API backend in a fixed, isolated environment.\n",
    "    Function calling lets you run the functions that the model requests, in whatever environment you want.\n",
    "\n",
    "In general you should prefer to use code execution if it can handle your use case. Code execution is simpler to use (you just enable it) and resolves in a single GenerateContent request (thus incurring a single charge). Function calling takes an additional GenerateContent request to send back the output from each function call (thus incurring multiple charges).\n",
    "\n",
    "For most cases, you should use function calling if you have your own functions that you want to run locally, and you should use code execution if you'd like the API to write and run Python code for you and return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hellloo = model.generate_content(\"1+1\")\n",
    "\n",
    "print(hellloo.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can write code to calculate that. First, I need a function to check if a number is prime. Then I can iterate through numbers, check if they're prime, and add them until I have 50 primes. \n",
      "\n",
      "\n",
      "``` python\n",
      "def is_prime(n):\n",
      "    \"\"\"Checks if n is a prime number (greater than 1)\"\"\"\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    for i in range(2, int(n**0.5) + 1):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "\n",
      "primes = []\n",
      "num = 2\n",
      "while len(primes) < 50:\n",
      "    if is_prime(num):\n",
      "        primes.append(num)\n",
      "    num += 1\n",
      "\n",
      "print(sum(primes))\n",
      "\n",
      "```\n",
      "```\n",
      "5117\n",
      "\n",
      "```\n",
      "The sum of the first 50 prime numbers is 5117. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "genai.configure(api_key=\"\")\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "    text = text.replace(\"•\", \"  *\")\n",
    "    return Markdown(textwrap.indent(text, \"> \", predicate=lambda _: True))\n",
    "\n",
    "\n",
    "code_model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\", tools=\"code_execution\")\n",
    "\n",
    "response = code_model.generate_content(\n",
    "    (\n",
    "        \"What is the sum of the first 50 prime numbers? \"\n",
    "        \"Generate and run code for the calculation, and make sure you get all 50.\"\n",
    "    ),\n",
    "    tools=\"code_execution\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_disco_ball(power: bool) -> bool:\n",
    "    \"\"\"Powers the spinning disco ball.\"\"\"\n",
    "    print(f\"Disco ball is {'spinning!' if power else 'stopped.'}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def start_music(energetic: bool, loud: bool, bpm: int) -> str:\n",
    "    \"\"\"Play some music matching the specified parameters.\n",
    "\n",
    "    Args:\n",
    "      energetic: Whether the music is energetic or not.\n",
    "      loud: Whether the music is loud or not.\n",
    "      bpm: The beats per minute of the music.\n",
    "\n",
    "    Returns: The name of the song being played.\n",
    "    \"\"\"\n",
    "    print(f\"Starting music! {energetic=} {loud=}, {bpm=}\")\n",
    "    return \"Never gonna give you up.\"\n",
    "\n",
    "\n",
    "def dim_lights(brightness: float) -> bool:\n",
    "    \"\"\"Dim the lights.\n",
    "\n",
    "    Args:\n",
    "      brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n",
    "    \"\"\"\n",
    "    print(f\"Lights are now set to {brightness:.0%}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "# Set the model up with tools.\n",
    "house_fns = [power_disco_ball, start_music, dim_lights]\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", tools=house_fns)\n",
    "\n",
    "# Call the API.\n",
    "chat = model.start_chat()\n",
    "response = chat.send_message(\"Turn this place into a party!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power_disco_ball(power=True)\n",
      "start_music(loud=True, energetic=True, bpm=120.0)\n",
      "dim_lights(brightness=0.5)\n"
     ]
    }
   ],
   "source": [
    "# Print out each of the function calls requested from this single call.\n",
    "for part in response.parts:\n",
    "    if fn := part.function_call:\n",
    "        args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
    "        print(f\"{fn.name}({args})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "whichOneof",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m response \u001b[38;5;241m=\u001b[39m chat\u001b[38;5;241m.\u001b[39msend_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm feeling sleepy, let\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms wind down.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\63916\\Downloads\\test-pk\\venv\\Lib\\site-packages\\google\\generativeai\\types\\generation_types.py:465\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    462\u001b[0m         texts\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutcome_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, part\u001b[38;5;241m.\u001b[39mcode_execution_result\u001b[38;5;241m.\u001b[39moutput, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m     part_type \u001b[38;5;241m=\u001b[39m \u001b[43mprotos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhichOneof\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert `part.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` to text.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(texts)\n",
      "\u001b[1;31mAttributeError\u001b[0m: whichOneof"
     ]
    }
   ],
   "source": [
    "# Simulate the responses from the specified tools.\n",
    "responses = {\n",
    "    \"power_disco_ball\": True,\n",
    "    \"start_music\": \"Never gonna give you up.\",\n",
    "    \"dim_lights\": True,\n",
    "}\n",
    "\n",
    "# Build the response parts.\n",
    "response_parts = [\n",
    "    genai.protos.Part(\n",
    "        function_response=genai.protos.FunctionResponse(\n",
    "            name=fn, response={\"result\": val}\n",
    "        )\n",
    "    )\n",
    "    for fn, val in responses.items()\n",
    "]\n",
    "\n",
    "response = chat.send_message(response_parts)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
