{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mic Recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press Enter to stop.\n",
      "Recording complete.\n",
      "Waiting for operation to complete...\n",
      "Transcript\n",
      "can you somehow find a way to make it. Streaming\n",
      " I really enjoy your day working a lot\n",
      " pretty tiring streaming\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "from google.cloud import speech\n",
    "import io\n",
    "import threading\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Initialize the Speech-to-Text client\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "# Function to record audio from the microphone\n",
    "def record_audio(temp_file_path):\n",
    "    # Setup parameters for the audio recording\n",
    "    chunk = 1024  # Record in chunks of 1024 samples\n",
    "    sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "    channels = 1\n",
    "    sample_rate = 24000  # Record at 24kHz\n",
    "    \n",
    "    p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "\n",
    "    print(\"Recording... Press Enter to stop.\")\n",
    "\n",
    "    # Open a new stream for recording\n",
    "    stream = p.open(format=sample_format,\n",
    "                    channels=channels,\n",
    "                    rate=sample_rate,\n",
    "                    frames_per_buffer=chunk,\n",
    "                    input=True)\n",
    "\n",
    "    frames = []  # Initialize array to store frames\n",
    "\n",
    "    # Function to read audio data in a loop\n",
    "    def read_audio():\n",
    "        while not stop_recording.is_set():\n",
    "            data = stream.read(chunk)\n",
    "            frames.append(data)\n",
    "\n",
    "    # Create a threading event to stop recording\n",
    "    stop_recording = threading.Event()\n",
    "\n",
    "    # Start the audio recording thread\n",
    "    recording_thread = threading.Thread(target=read_audio)\n",
    "    recording_thread.start()\n",
    "\n",
    "    # Wait for user input to stop recording\n",
    "    input()\n",
    "    stop_recording.set()\n",
    "    recording_thread.join()\n",
    "\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    print(\"Recording complete.\")\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    with wave.open(temp_file_path, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "# Function to transcribe audio using Google Cloud Speech-to-Text\n",
    "def transcribe_audio(temp_file_path):\n",
    "    # Read the audio file\n",
    "    with io.open(temp_file_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "    \n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=24000,\n",
    "        language_code=\"ceb-PH\",\n",
    "        model=\"default\",\n",
    "        audio_channel_count=1,\n",
    "        enable_word_confidence=True,\n",
    "        enable_word_time_offsets=True,\n",
    "    )\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "    response = operation.result(timeout=90)\n",
    "\n",
    "    print(\"Transcript\")\n",
    "    for result in response.results:\n",
    "        print(result.alternatives[0].transcript)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "        temp_file_path = temp_file.name\n",
    "\n",
    "    try:\n",
    "        record_audio(temp_file_path)\n",
    "        transcribe_audio(temp_file_path)\n",
    "    finally:\n",
    "        os.remove(temp_file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import texttospeech\n",
    "\n",
    "def synthesize_text(text):\n",
    "    \"\"\"Synthesizes speech from the input string of text.\"\"\"\n",
    "\n",
    "\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "    input_text = texttospeech.SynthesisInput(text=text)\n",
    "\n",
    "    # Note: the voice can also be specified by name.\n",
    "    # Names of voices can be retrieved with client.list_voices().\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        name=\"en-US-Standard-C\",\n",
    "        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE,\n",
    "    )\n",
    "\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "\n",
    "    response = client.synthesize_speech(\n",
    "        request={\"input\": input_text, \"voice\": voice, \"audio_config\": audio_config}\n",
    "    )\n",
    "\n",
    "    # The response's audio_content is binary.\n",
    "    with open(\"output.mp3\", \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "        print('Audio content written to file \"output.mp3\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio content written to file \"output.mp3\"\n"
     ]
    }
   ],
   "source": [
    "synthesize_text(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press Enter to stop.\n",
      "Recording complete.\n",
      "Transcribing audio...\n",
      "User said: hello I am testing this out\n",
      "AI response: Hello there! I'm glad you're here to test me out. I'm eager to engage in a thought-provoking debate or lend my support in defending an idea. Please feel free to present your stance, and I'll do my best to stimulate a lively and enriching conversation. Let's get started!\n",
      "Audio response saved as \"response.mp3\"\n",
      "Recording... Press Enter to stop.\n",
      "Recording complete.\n",
      "Transcribing audio...\n",
      "User said: so I think abortion should be illegal\n",
      "AI response: Abortion is a complex and highly personal issue. There are many different beliefs about when life begins, and what rights a fetus has. It is important to be respectful of all opinions on this topic, even if you disagree with them.\n",
      "\n",
      "One of the main reasons why people believe abortion should be illegal is because they believe that life begins at conception. They argue that a fetus is a human being with the same rights as any other human, and that abortion is therefore murder.\n",
      "\n",
      "Others believe that abortion should be legal because they believe that a woman has the right to control her own body. They argue that the government should not interfere in a woman's decision to have an abortion.\n",
      "\n",
      "There is no easy answer to the question of whether or not abortion should be legal. It is a complex issue with many different perspectives. It is important to be respectful of all opinions on this topic, even if you disagree with them.\n",
      "Audio response saved as \"response.mp3\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyaudio\n",
    "import wave\n",
    "import io\n",
    "import threading\n",
    "import tempfile\n",
    "from google.cloud import speech\n",
    "from google.cloud import texttospeech\n",
    "import google.generativeai as genai\n",
    "import random\n",
    "\n",
    "# Initialize the Speech-to-Text client\n",
    "speech_client = speech.SpeechClient()\n",
    "\n",
    "# Initialize the Text-to-Speech client\n",
    "tts_client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "# Initialize Gemini API\n",
    "genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "def record_audio(temp_file_path):\n",
    "    # Setup parameters for the audio recording\n",
    "    chunk = 1024\n",
    "    sample_format = pyaudio.paInt16\n",
    "    channels = 1\n",
    "    sample_rate = 24000\n",
    "    \n",
    "    p = pyaudio.PyAudio()\n",
    "    print(\"Recording... Press Enter to stop.\")\n",
    "    \n",
    "    stream = p.open(format=sample_format,\n",
    "                    channels=channels,\n",
    "                    rate=sample_rate,\n",
    "                    frames_per_buffer=chunk,\n",
    "                    input=True)\n",
    "    \n",
    "    frames = []\n",
    "    stop_recording = threading.Event()\n",
    "    \n",
    "    def read_audio():\n",
    "        while not stop_recording.is_set():\n",
    "            data = stream.read(chunk)\n",
    "            frames.append(data)\n",
    "    \n",
    "    recording_thread = threading.Thread(target=read_audio)\n",
    "    recording_thread.start()\n",
    "    \n",
    "    input()\n",
    "    stop_recording.set()\n",
    "    recording_thread.join()\n",
    "    \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    \n",
    "    print(\"Recording complete.\")\n",
    "    \n",
    "    with wave.open(temp_file_path, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "def transcribe_audio(temp_file_path):\n",
    "    with io.open(temp_file_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "    \n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=24000,\n",
    "        language_code=\"en-US\",\n",
    "        model=\"default\",\n",
    "        audio_channel_count=1,\n",
    "        enable_word_confidence=True,\n",
    "        enable_word_time_offsets=True,\n",
    "    )\n",
    "    \n",
    "    operation = speech_client.long_running_recognize(config=config, audio=audio)\n",
    "    print(\"Transcribing audio...\")\n",
    "    response = operation.result(timeout=90)\n",
    "    \n",
    "    transcript = \"\"\n",
    "    for result in response.results:\n",
    "        transcript += result.alternatives[0].transcript + \" \"\n",
    "    \n",
    "    return transcript.strip()\n",
    "\n",
    "def synthesize_speech(text):\n",
    "    input_text = texttospeech.SynthesisInput(text=text)\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        name=\"en-US-Standard-C\",\n",
    "        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE,\n",
    "    )\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "    \n",
    "    response = tts_client.synthesize_speech(\n",
    "        input=input_text, voice=voice, audio_config=audio_config\n",
    "    )\n",
    "    \n",
    "    with open(\"response.mp3\", \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "    print('Audio response saved as \"response.mp3\"')\n",
    "\n",
    "def generate_ai_response(user_input, mode):\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI communication assistant. Based on the user's input, your task is to {mode}. \n",
    "    Respond in a way that encourages further conversation and helps the user improve their communication skills.\n",
    "\n",
    "    User input: {user_input}\n",
    "\n",
    "    Your response:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "            temp_file_path = temp_file.name\n",
    "        \n",
    "        try:\n",
    "            record_audio(temp_file_path)\n",
    "            user_input = transcribe_audio(temp_file_path)\n",
    "            print(f\"User said: {user_input}\")\n",
    "            \n",
    "            mode = input(\"Choose mode (1: Debate, 2: Explain, 3: Storytelling, 4: Q&A): \")\n",
    "            modes = {\n",
    "                \"1\": \"debate or defend the idea presented\",\n",
    "                \"2\": \"explain the concept using metaphors and without circular reasoning\",\n",
    "                \"3\": \"create a narrative or story based on the input\",\n",
    "                \"4\": \"formulate relevant questions or provide answers based on the input\"\n",
    "            }\n",
    "            \n",
    "            ai_response = generate_ai_response(user_input, modes.get(mode, \"have a general conversation about\"))\n",
    "            print(f\"AI response: {ai_response}\")\n",
    "            \n",
    "            synthesize_speech(ai_response)\n",
    "            \n",
    "            continue_chat = input(\"Continue chatting? (y/n): \").lower()\n",
    "            if continue_chat != 'y':\n",
    "                break\n",
    "        \n",
    "        finally:\n",
    "            os.remove(temp_file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from google.cloud import speech, texttospeech\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import tempfile\n",
    "import base64\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Initialize clients\n",
    "speech_client = speech.SpeechClient()\n",
    "tts_client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "# Initialize Gemini API\n",
    "genai.configure(api_key=\"YOUR_GEMINI_API_KEY\")\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "def transcribe_audio(audio_content):\n",
    "    audio = speech.RecognitionAudio(content=audio_content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=24000,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "    response = speech_client.recognize(config=config, audio=audio)\n",
    "    return response.results[0].alternatives[0].transcript\n",
    "\n",
    "def synthesize_text(text):\n",
    "    input_text = texttospeech.SynthesisInput(text=text)\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        name=\"en-US-Standard-C\",\n",
    "        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE,\n",
    "    )\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "    response = tts_client.synthesize_speech(\n",
    "        input=input_text, voice=voice, audio_config=audio_config\n",
    "    )\n",
    "    return base64.b64encode(response.audio_content).decode('utf-8')\n",
    "\n",
    "def gemini_process(user_input, mode):\n",
    "    prompt = f\"\"\"\n",
    "    Respond to the user's input in a conversational manner, keeping the response around 5 seconds long when spoken.\n",
    "    Focus on the following mode: {mode}\n",
    "\n",
    "    1. Debate/Defend: Provide a counterargument or supporting argument.\n",
    "    2. Narrate/Storytell: Create a brief narrative or story element related to the input.\n",
    "    3. Explain: Use a metaphor or analogy to explain the concept.\n",
    "    4. Question Formation/Answering: Generate a relevant question or provide a concise answer.\n",
    "\n",
    "    User input: {user_input}\n",
    "    \"\"\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "@app.route('/process_audio', methods=['POST'])\n",
    "def process_audio():\n",
    "    audio_data = request.files['audio'].read()\n",
    "    mode = request.form['mode']\n",
    "    \n",
    "    user_input = transcribe_audio(audio_data)\n",
    "    ai_response = gemini_process(user_input, mode)\n",
    "    audio_response = synthesize_text(ai_response)\n",
    "    \n",
    "    return jsonify({\n",
    "        'user_input': user_input,\n",
    "        'ai_response': ai_response,\n",
    "        'audio_response': audio_response\n",
    "    })\n",
    "\n",
    "@app.route('/get_prompt', methods=['GET'])\n",
    "def get_prompt():\n",
    "    prompts = [\n",
    "        \"Discuss a recent technological advancement that excites you.\",\n",
    "        \"Share your thoughts on the future of remote work.\",\n",
    "        \"What's a book or movie that has greatly influenced your thinking?\",\n",
    "        \"Describe an interesting cultural tradition from your background.\",\n",
    "        \"If you could solve one global problem, what would it be and why?\"\n",
    "    ]\n",
    "    return jsonify({'prompt': random.choice(prompts)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\63916\\Downloads\\test-pk\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
