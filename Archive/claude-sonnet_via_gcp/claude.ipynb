{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"padayon-ko-gemini\"\n",
    "LOCATION = \"us-east5\"\n",
    "MODEL = \"claude-3-5-sonnet@20240620\"\n",
    "\n",
    "ENDPOINT = f\"https://{LOCATION}-aiplatform.googleapis.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a function that creates an interactive chat interface using IPython widgets to interact with the Claude API within a Jupyter notebook, with output rendered as Markdown in VSCode:\n",
      "\n",
      "```python\n",
      "import ipywidgets as widgets\n",
      "from IPython.display import display, Markdown\n",
      "from anthropic import AnthropicVertex\n",
      "\n",
      "def claude_chat(location, project_id, model):\n",
      "    client = AnthropicVertex(region=location, project_id=project_id)\n",
      "    \n",
      "    conversation_history = []\n",
      "\n",
      "    def on_send(button):\n",
      "        user_input = input_box.value\n",
      "        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
      "        \n",
      "        with client.messages.stream(\n",
      "            max_tokens=4096,\n",
      "            messages=conversation_history,\n",
      "            model=model,\n",
      "        ) as stream:\n",
      "            response = \"\"\n",
      "            for text in stream.text_stream:\n",
      "                response += text\n",
      "                output.value = f\"**Claude:** {response}\"\n",
      "        \n",
      "        conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
      "        input_box.value = \"\"\n",
      "\n",
      "    input_box = widgets.Text(placeholder=\"Type your message here...\")\n",
      "    send_button = widgets.Button(description=\"Send\")\n",
      "    send_button.on_click(on_send)\n",
      "    output = widgets.HTML()\n",
      "\n",
      "    display(widgets.VBox([input_box, send_button, output]))\n",
      "\n",
      "# Usage:\n",
      "# claude_chat(LOCATION, PROJECT_ID, MODEL)\n",
      "```\n",
      "\n",
      "To use this function, you would call it with your GCP location, project ID, and the desired Claude model:\n",
      "\n",
      "```python\n",
      "claude_chat(\"us-central1\", \"your-project-id\", \"claude-3-sonnet-20240229\")\n",
      "```\n",
      "\n",
      "This function does the following:\n",
      "\n",
      "1. It creates an interactive interface using IPython widgets.\n",
      "2. It maintains a conversation history to provide context for each new message.\n",
      "3. When you type a message and click \"Send\", it sends the message to Claude along with the conversation history.\n",
      "4. Claude's response is streamed and displayed in real-time as Markdown.\n",
      "5. The conversation history is updated with each exchange.\n",
      "\n",
      "The output will be rendered as Markdown in VSCode's Markdown preview for .ipynb files.\n",
      "\n",
      "Note: Make sure you have the `ipywidgets` package installed (`pip install ipywidgets`) for this to work properly.\n",
      "\n",
      "Also, ensure that you have the necessary permissions and authentication set up for your GCP project to use AnthropicVertex."
     ]
    }
   ],
   "source": [
    "from anthropic import AnthropicVertex\n",
    "\n",
    "client = AnthropicVertex(region=LOCATION, project_id=PROJECT_ID)\n",
    "\n",
    "with client.messages.stream(\n",
    "    max_tokens=4096,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "            make function with an ipython display so i can interact with claude api calls within an ipynb with output printed to markdown with markdown rendered in vscode markdown ipynb. no need for API key im using GCP\n",
    "            from anthropic import AnthropicVertex\n",
    "\n",
    "client = AnthropicVertex(region=LOCATION, project_id=PROJECT_ID)\n",
    "\n",
    "with client.messages.stream(\n",
    "    max_tokens=4096,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"with \"memory\" or ability to access history. i want to make a mini llm CHAT interface. make function with an ipython display so i can interact with claude api calls within an ipynb,\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL,\n",
    ") as stream:\n",
    "    for text in stream.text_stream:\n",
    "        print(text, end=\"\", flush=True)\n",
    "            \"\"\",\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL,\n",
    ") as stream:\n",
    "    for text in stream.text_stream:\n",
    "        print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb6d9287c2b4ad38a22e7be11fb6383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', placeholder='Type your message here...'), Button(description='Send', style=Buttoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, Code\n",
    "from anthropic import AnthropicVertex\n",
    "import re\n",
    "\n",
    "PROJECT_ID = \"padayon-ko-gemini\"\n",
    "LOCATION = \"us-east5\"\n",
    "MODEL = \"claude-3-5-sonnet@20240620\"\n",
    "\n",
    "ENDPOINT = f\"https://{LOCATION}-aiplatform.googleapis.com\"\n",
    "\n",
    "\n",
    "def claude_chat(location, project_id, model):\n",
    "    client = AnthropicVertex(region=location, project_id=project_id)\n",
    "    conversation_history = []\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    def on_send(button):\n",
    "        user_input = input_box.value\n",
    "        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        with output_area:\n",
    "            display(Markdown(f\"**You:** {user_input}\"))\n",
    "\n",
    "        with client.messages.stream(\n",
    "            max_tokens=4096,\n",
    "            messages=conversation_history,\n",
    "            model=model,\n",
    "        ) as stream:\n",
    "            response = \"\"\n",
    "            code_block = \"\"\n",
    "            in_code_block = False\n",
    "\n",
    "            for text in stream.text_stream:\n",
    "                response += text\n",
    "\n",
    "                if \"```\" in text:\n",
    "                    in_code_block = not in_code_block\n",
    "                    if not in_code_block and code_block:\n",
    "                        with output_area:\n",
    "                            lang = re.match(r\"```(\\w+)\", code_block)\n",
    "                            code = re.sub(r\"```\\w*\\n?\", \"\", code_block).strip()\n",
    "                            display(\n",
    "                                Code(\n",
    "                                    data=code, language=lang.group(1) if lang else None\n",
    "                                )\n",
    "                            )\n",
    "                        code_block = \"\"\n",
    "                elif in_code_block:\n",
    "                    code_block += text\n",
    "                else:\n",
    "                    with output_area:\n",
    "                        display(Markdown(text), display_id=True)\n",
    "\n",
    "            if code_block:\n",
    "                with output_area:\n",
    "                    lang = re.match(r\"```(\\w+)\", code_block)\n",
    "                    code = re.sub(r\"```\\w*\\n?\", \"\", code_block).strip()\n",
    "                    display(Code(data=code, language=lang.group(1) if lang else None))\n",
    "\n",
    "            conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "        input_box.value = \"\"\n",
    "\n",
    "    input_box = widgets.Text(placeholder=\"Type your message here...\")\n",
    "    send_button = widgets.Button(description=\"Send\")\n",
    "    send_button.on_click(on_send)\n",
    "\n",
    "    display(widgets.VBox([input_box, send_button, output_area]))\n",
    "\n",
    "\n",
    "# Usage:\n",
    "claude_chat(LOCATION, PROJECT_ID, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
